{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358eb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NOTEBOOK 3: FEATURE ENGINEERING - ATO Risk Profiler\n",
    "# ============================================================\n",
    "# Goal: Create predictive features from raw transaction data.\n",
    "# Key Features:\n",
    "#   - Velocity (speed of transactions)\n",
    "#   - Aggregations (user history)\n",
    "#   - Time & Behavior patterns\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../data/simulated_transactions.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort by user and time (Crucial for lag features)\n",
    "df = df.sort_values(['user_id', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset loaded & sorted\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29150e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. TIME-BASED FEATURES\n",
    "# ============================================================\n",
    "\n",
    "# Basic extraction\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Cyclical encoding for Hour (Preserves 23:00 -> 00:00 proximity)\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "# Time since last transaction (per user)\n",
    "df['time_diff_seconds'] = df.groupby('user_id')['timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "print(\"âœ… Time features created:\")\n",
    "print(df[['timestamp', 'hour', 'is_weekend', 'hour_sin', 'time_diff_seconds']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. VELOCITY FEATURES (Rolling Windows)\n",
    "# ============================================================\n",
    "# How many transactions did this user do in the last X hours?\n",
    "\n",
    "# Set index for rolling\n",
    "df_rolling = df.set_index('timestamp').groupby('user_id')\n",
    "\n",
    "# Count transactions in last 1 hour, 24 hours, 7 days\n",
    "# Note: '1h' requires time index\n",
    "df['tx_count_1h'] = df_rolling['amount'].rolling('1h').count().values\n",
    "df['tx_count_24h'] = df_rolling['amount'].rolling('24h').count().values\n",
    "df['tx_count_7d'] = df_rolling['amount'].rolling('7d').count().values\n",
    "\n",
    "# Sum of amount in last 24h\n",
    "df['amount_sum_24h'] = df_rolling['amount'].rolling('24h').sum().values\n",
    "\n",
    "print(\"âœ… Velocity features created (tx counts per window)\")\n",
    "display(df[['user_id', 'timestamp', 'tx_count_1h', 'tx_count_24h']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a9669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. BEHAVIORAL AGGREGATIONS (User History)\n",
    "# ============================================================\n",
    "# Comparing current transaction vs user's historical average\n",
    "\n",
    "# Calculate historical average amount (expanding window to avoid data leakage)\n",
    "df['avg_amount_history'] = df.groupby('user_id')['amount'].expanding().mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Ratio: Current Amount / Average Amount\n",
    "# High ratio (>3 or >5) indicates potential anomaly\n",
    "df['amount_ratio'] = df['amount'] / df['avg_amount_history']\n",
    "df['amount_ratio'] = df['amount_ratio'].fillna(1) # Handle first transaction\n",
    "\n",
    "# Device change tracking\n",
    "# 1 if device changed from previous transaction, 0 otherwise\n",
    "df['device_changed'] = (df.groupby('user_id')['device_type'].shift(1) != df['device_type']).astype(int)\n",
    "\n",
    "# Country change tracking\n",
    "df['country_changed'] = (df.groupby('user_id')['merchant_country'].shift(1) != df['merchant_country']).astype(int)\n",
    "\n",
    "print(\"âœ… Behavioral features created\")\n",
    "display(df[['user_id', 'amount', 'avg_amount_history', 'amount_ratio', 'device_changed']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef48113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. GEO-VELOCITY (Simplified Impossible Travel)\n",
    "# ============================================================\n",
    "# Did the user change country in a very short time?\n",
    "\n",
    "# Create a risk flag if:\n",
    "# Country changed AND time difference < 2 hours (7200 seconds)\n",
    "# This is a strong indicator of VPN/Proxy or Simultaneous Login (ATO)\n",
    "\n",
    "df['quick_country_change'] = (\n",
    "    (df['country_changed'] == 1) & \n",
    "    (df['time_diff_seconds'] < 7200) & \n",
    "    (df['time_diff_seconds'] > 0) # Ignore same timestamp\n",
    ").astype(int)\n",
    "\n",
    "# Check how many flagged\n",
    "print(f\"ðŸš© Suspicious 'Impossible Travel' events found: {df['quick_country_change'].sum()}\")\n",
    "\n",
    "# Inspect some cases\n",
    "display(df[df['quick_country_change'] == 1][['user_id', 'timestamp', 'merchant_country', 'time_diff_seconds', 'is_fraud']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. CLEANUP & EXPORT\n",
    "# ============================================================\n",
    "\n",
    "# Select columns for Model Training\n",
    "features = [\n",
    "    'amount', 'hour_sin', 'hour_cos', 'day_of_week', 'is_weekend', # Time\n",
    "    'tx_count_1h', 'tx_count_24h', 'tx_count_7d', 'amount_sum_24h', # Velocity\n",
    "    'time_diff_seconds', 'amount_ratio', # Behavior\n",
    "    'device_changed', 'country_changed', 'quick_country_change' # Risk Flags\n",
    "]\n",
    "\n",
    "target = 'is_fraud'\n",
    "meta = ['transaction_id', 'user_id', 'timestamp', 'fraud_type'] # Metadata to keep but not train on\n",
    "\n",
    "# Final DataFrame\n",
    "df_final = df[meta + features + [target]].copy()\n",
    "\n",
    "# Fill NaNs if any (usually first transactions)\n",
    "df_final = df_final.fillna(0)\n",
    "\n",
    "print(f\"âœ… Final Feature Set Ready: {df_final.shape}\")\n",
    "print(f\"   Features: {len(features)}\")\n",
    "print(f\"   Target: {target}\")\n",
    "\n",
    "# Save to processed data folder\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "df_final.to_csv('../data/processed/features_engineered.csv', index=False)\n",
    "print(\"\\nðŸ’¾ Saved to: data/processed/features_engineered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc581f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VALIDATION: Feature Power (Clean Boxplots)\n",
    "# ============================================================\n",
    "\n",
    "# Features to analyze (Using 7-day velocity for better spread)\n",
    "features_to_check = ['amount_ratio', 'time_diff_seconds', 'tx_count_7d']\n",
    "feature_names = ['Amount Ratio (vs Avg)', 'Time Since Last Tx (Sec)', 'Velocity (7-day count)']\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "for i, col in enumerate(features_to_check):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    \n",
    "    # Boxplot with outliers suppressed\n",
    "    sns.boxplot(\n",
    "        x='is_fraud', y=col, hue='is_fraud', data=df_final, \n",
    "        palette=[\"#3498db\", \"#e74c3c\"], \n",
    "        showfliers=False, \n",
    "        width=0.5,\n",
    "        legend=False\n",
    "    )\n",
    "    \n",
    "    plt.title(f'Discriminative Power:\\n{feature_names[i]}', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Class (0=Legit, 1=Fraud)', fontsize=10)\n",
    "    plt.ylabel('Feature Value', fontsize=10)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print median comparison to confirm separation numerically\n",
    "print(\"Median Values Comparison (Fraud vs Legit):\")\n",
    "medians = df_final.groupby('is_fraud')[features_to_check].median()\n",
    "display(medians)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
