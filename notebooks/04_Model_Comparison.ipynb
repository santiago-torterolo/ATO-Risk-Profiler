{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7668df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NOTEBOOK 4: MODEL TRAINING & COMPARISON\n",
    "# ============================================================\n",
    "# Goal: Train and evaluate multiple models to detect ATO fraud.\n",
    "# Models:\n",
    "#   1. Logistic Regression (Baseline)\n",
    "#   2. Random Forest (Robust Ensemble)\n",
    "#   3. XGBoost (Gradient Boosting - Industry Standard)\n",
    "#   4. Isolation Forest (Unsupervised Anomaly Detection)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Configuration\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load engineered features\n",
    "df = pd.read_csv('../data/processed/features_engineered.csv')\n",
    "\n",
    "print(\"Data Loaded\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Fraud Rate: {df['is_fraud'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA PREPARATION\n",
    "# ============================================================\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['transaction_id', 'user_id', 'timestamp', 'fraud_type', 'is_fraud'], axis=1)\n",
    "y = df['is_fraud']\n",
    "\n",
    "# Split data (80% Train, 20% Test)\n",
    "# Stratify is crucial for imbalanced datasets to keep fraud ratio consistent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features (RobustScaler handles outliers better than StandardScaler)\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data Split & Scaled\")\n",
    "print(f\"Train Set: {X_train.shape[0]} samples ({y_train.sum()} frauds)\")\n",
    "print(f\"Test Set:  {X_test.shape[0]} samples ({y_test.sum()} frauds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EVALUATION HELPER FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_model(name, model, X_test, y_test, y_pred, y_prob=None):\n",
    "    \"\"\"\n",
    "    Calculates and prints key metrics for fraud detection.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred) # Critical for fraud (catch rate)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"----- {name} Results -----\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f} (Low false positives)\")\n",
    "    print(f\"Recall:    {recall:.4f} (High detection rate)\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    auc = None\n",
    "    if y_prob is not None:\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        print(f\"ROC-AUC:   {auc:.4f}\")\n",
    "        \n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'AUC': auc\n",
    "    }\n",
    "\n",
    "print(\"Helper function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fee7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SUPERVISED LEARNING MODELS\n",
    "# ============================================================\n",
    "results_list = []\n",
    "models = {}\n",
    "\n",
    "# 1. Logistic Regression (Baseline)\n",
    "# class_weight='balanced' helps with the 3% fraud rate\n",
    "lr = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "y_prob_lr = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "results_list.append(evaluate_model(\"Logistic Regression\", lr, X_test_scaled, y_test, y_pred_lr, y_prob_lr))\n",
    "models['Logistic Regression'] = lr\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train) # Tree models don't strictly need scaling\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "results_list.append(evaluate_model(\"Random Forest\", rf, X_test, y_test, y_pred_rf, y_prob_rf))\n",
    "models['Random Forest'] = rf\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. XGBoost\n",
    "# scale_pos_weight = ratio of negative/positive classes (~32 for 3% fraud)\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, scale_pos_weight=ratio, random_state=42, n_jobs=-1)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_prob_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "results_list.append(evaluate_model(\"XGBoost\", xgb, X_test, y_test, y_pred_xgb, y_prob_xgb))\n",
    "models['XGBoost'] = xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82730c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# UNSUPERVISED ANOMALY DETECTION\n",
    "# ============================================================\n",
    "# Isolation Forest doesn't use labels (y_train) for training!\n",
    "# It tries to find \"outliers\" based on feature distribution.\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.03, random_state=42, n_jobs=-1)\n",
    "iso_forest.fit(X_train_scaled) # Unsupervised fit\n",
    "\n",
    "# Predict (-1 is anomaly, 1 is normal) -> Convert to (1 is fraud, 0 is normal)\n",
    "y_pred_iso_raw = iso_forest.predict(X_test_scaled)\n",
    "y_pred_iso = [1 if x == -1 else 0 for x in y_pred_iso_raw]\n",
    "\n",
    "# Isolation Forest doesn't output probability like supervised models\n",
    "# But decision_function gives anomaly score (lower is more anomalous)\n",
    "y_scores_iso = -iso_forest.decision_function(X_test_scaled) \n",
    "\n",
    "results_list.append(evaluate_model(\"Isolation Forest\", iso_forest, X_test_scaled, y_test, y_pred_iso, y_scores_iso))\n",
    "models['Isolation Forest'] = iso_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MODEL COMPARISON DASHBOARD\n",
    "# ============================================================\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "print(\"Summary Table:\")\n",
    "display(results_df.sort_values('AUC', ascending=False))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Prepare data for plotting (melt)\n",
    "results_melt = results_df.melt(id_vars='Model', value_vars=['Precision', 'Recall', 'AUC'], \n",
    "                               var_name='Metric', value_name='Score')\n",
    "\n",
    "sns.barplot(x='Metric', y='Score', hue='Model', data=results_melt, palette='viridis')\n",
    "plt.title('Model Performance Comparison', fontsize=14)\n",
    "plt.ylim(0.5, 1.0) # Zoom in on the top half\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a846f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ROC CURVES (Visualizing Trade-offs)\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot ROC for each model\n",
    "# LR\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {results_df.iloc[0][\"AUC\"]:.2f})')\n",
    "\n",
    "# RF\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {results_df.iloc[1][\"AUC\"]:.2f})')\n",
    "\n",
    "# XGB\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {results_df.iloc[2][\"AUC\"]:.2f})')\n",
    "\n",
    "# IsoForest\n",
    "fpr_iso, tpr_iso, _ = roc_curve(y_test, y_scores_iso)\n",
    "plt.plot(fpr_iso, tpr_iso, label=f'Isolation Forest (AUC = {results_df.iloc[3][\"AUC\"]:.2f})', linestyle='--')\n",
    "\n",
    "# Random Guess line\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('ROC Curves: Supervised vs Unsupervised')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51233603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFUSION MATRIX (Best Model: XGBoost)\n",
    "# ============================================================\n",
    "\n",
    "best_model_name = \"XGBoost\" # Usually the winner\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted Legit', 'Predicted Fraud'],\n",
    "            yticklabels=['Actual Legit', 'Actual Fraud'])\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed34c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FEATURE IMPORTANCE (What drives fraud?)\n",
    "# ============================================================\n",
    "\n",
    "# Get feature importance from XGBoost\n",
    "importances = xgb.feature_importances_\n",
    "feature_names = X.columns\n",
    "feat_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feat_imp = feat_imp.sort_values('Importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp, palette='magma')\n",
    "plt.title('Top 10 Features for Detecting ATO Fraud (XGBoost)')\n",
    "plt.show()\n",
    "\n",
    "# Save best model\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "joblib.dump(xgb, '../models/best_model_xgboost.pkl')\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print(\"Best model and scaler saved to 'models/' folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
